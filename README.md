# log_analysis

## 배경
자료구조/알고리즘 공부 후, 적용할 수 있는 간단한 프로젝트. 

## 소개
임의로 만든 서버 로그파일(smaple.log)을 파싱하여 Top10 IP, Top10 Request, 가장 요청이 많은 시간대, 404 에러 발생 횟수를 분석하여 출력하는 프로그램 제작

## 로직 구현 과정
카운팅 기능은 hashmap(파이썬에선 dict)를 이용.

어떻게 Top10을 구할지에 대해 다음 고민이 있었다.
0. 정렬할 필요가 있어 Sequence 자료구조가 필요했다.
1. array, linked list 중 어떤것이 적절한가.
2. 정렬 상태를 유지할지, 아니면 필요시 정렬해야하나.

위 질문들을 고민하고 내린 결론은 다음과 같다.
| 자료구조 | 정렬 방식 | 업데이트 (IP 1건 처리) | Top-K 출력 | 공간 복잡도 | 비고 (결론) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **(A) 동적 배열** | **필요시 정렬** | **O(1)** (해시맵만 수정) | **O(n log n)** (전체 정렬) | **O(n)** | **서버 환경에 적합하고, 메모리적으로 안전한 선택.** |
| 동적 배열 | 정렬 유지 | O(n) (데이터 밀어내기) | O(k) (앞에서 K개) | O(n) | 업데이트가 너무 비효율적. |
| 연결 리스트 | 필요시 정렬 | O(1) (해시맵만 수정) | O(n log n) (배열보다 정렬이 불리) | O(n) | 배열 (A)안보다 장점이 없음. |
| **(B) 연결 리스트** | **정렬 유지** | **O(n)** (최악의 경우 Head까지 이동) | **O(k)** (앞에서 K개) | **O(n)** | **업데이트 비용 O(n)이 치명적.**|

## 결론과 이유
결론: (A)를 선택   
이유는 서버 로그 파일에서 정렬하는 경우보다 IP, Request마다 카운팅하는 일이 훨씬 많이 일어날 것이라 예상했기 때문이다. 
그렇다면 업데이트 비용이 저렴한 방법이 상황에 알맞다. 연결 리스트에 경우, 동일한 횟수를 갖는 노드들이 많은 경우 버블 정렬처럼 O(n) 비교가 수행될 수 있다.

횟수(>=1)인 특징을 이용해 bucket sort를 적용할수도 있지만, 공간 복잡도가 O(k)를 따르는데 O(n)보다 훨씬 큰 공간이 필요해질 수 있다. (k는 횟수중 최댓값, n은 유니크한 키 갯수)
예를 들면, 로그에 192.0.0.1 IP에서만 10만번의 요청만 있다면, 최대값때문에 10만+ 1 만큼의 메모리가 필요해진다. 반면, O(n) 공간 복잡도라면 정렬시 공간 1개만 있으면 된다. 
